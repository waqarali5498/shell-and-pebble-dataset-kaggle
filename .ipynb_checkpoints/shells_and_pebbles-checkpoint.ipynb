{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a8bbd00-928f-497d-91a3-2816f577300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D , Flatten , Dense ,BatchNormalization , Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a721e84-9ab8-4ac2-ad61-cad833184785",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential([\n",
    "    # 77 75\n",
    "    \n",
    "    tf.keras.layers.Input(shape=(256, 256, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Ensure this layer outputs a single value\n",
    "\n",
    "\n",
    "    # Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=[64, 64, 3]),\n",
    "    # # BatchNormalization(),\n",
    "    # MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    # # BatchNormalization(),\n",
    "    # MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # # Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    # # # BatchNormalization(),\n",
    "    # # MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "\n",
    "    \n",
    "    # Flatten(),\n",
    "    # # Dropout(0.5),\n",
    "    # Dense(128, activation='relu'),\n",
    "    # # Dropout(0.5),\n",
    "    # # Dense(256, activation='relu'),\n",
    "    # # Dropout(0.5),\n",
    "    # # Dense(128, activation='relu'),\n",
    "    # # Dense(64, activation='relu'),\n",
    "    # # Dense(32, activation='relu'),\n",
    "    # Dense(1, activation='sigmoid')  # Output Layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1679c1a9-8ba9-48a7-b1f9-f677110fdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7cc0eec-aeb4-4044-9a35-dce9fcf1cc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3426 images belonging to 2 classes.\n",
      "Found 858 images belonging to 2 classes.\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m history \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     45\u001b[0m     training_set,\n\u001b[0;32m     46\u001b[0m     steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m3426\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m32\u001b[39m),       \u001b[38;5;66;03m# Convert to integer\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[0;32m     48\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mtest_set,\n\u001b[0;32m     49\u001b[0m     validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m720\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m32\u001b[39m),      \u001b[38;5;66;03m# Convert to integer\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, model_checkpoint]\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:121\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[1;32m--> 121\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    122\u001b[0m     one_step_on_data, args\u001b[38;5;241m=\u001b[39m(data,)\n\u001b[0;32m    123\u001b[0m )\n\u001b[0;32m    124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[0;32m    125\u001b[0m     outputs,\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[0;32m    127\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    128\u001b[0m )\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[1;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Image augmentation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,                # Rescale pixel values from [0, 255] to [0, 1]\n",
    "    shear_range=0.2,               # Apply random shear transformations\n",
    "    zoom_range=0.2,                # Apply random zoom transformations\n",
    "    horizontal_flip=True           # Randomly flip images horizontally\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)  # Only rescale test/validation data\n",
    "\n",
    "# Load images\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/train',        # Directory with training images\n",
    "    target_size=(64, 64),          # Resize all images to 64x64\n",
    "    batch_size=32,                 # Number of images to be yielded from the generator per batch\n",
    "    class_mode='binary'            # Type of label arrays to be returned ('binary' for binary classification)\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test',            # Directory with test/validation images\n",
    "    target_size=(64, 64),          # Resize all images to 64x64\n",
    "    batch_size=32,                 # Number of images to be yielded from the generator per batch\n",
    "    class_mode='binary'            # Type of label arrays to be returned ('binary' for binary classification)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "# model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = classifier.fit(\n",
    "    training_set,\n",
    "    steps_per_epoch=int(3426/32),       # Convert to integer\n",
    "    epochs=25,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=int(720/32),      # Convert to integer\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a16554f3-73b5-449b-938a-4fb2728c6791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "The image at dataset/predict.jpg is a Pebble\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load the trained model\n",
    "# model = tf.keras.models.load_model('best_model.keras')\n",
    "\n",
    "def predict_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(64, 64))  # Load and resize the image\n",
    "    img_array = image.img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Rescale the image\n",
    "\n",
    "    prediction = classifier.predict(img_array)  # Predict the class\n",
    "    if prediction[0] > 0.5:\n",
    "        print(f\"The image at {image_path} is a Shell\")\n",
    "    else:\n",
    "        print(f\"The image at {image_path} is a Pebble\")\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dataset/predict.jpg'  # Path to the image to be predicted\n",
    "predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3c049423-fd54-44c2-9646-f69a701ad3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "The image at dataset/r.jpg is a Shell\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "image_path = 'dataset/r.jpg'  # Path to the image to be predicted\n",
    "predict_image(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
